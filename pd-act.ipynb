{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10807429,"sourceType":"datasetVersion","datasetId":6708519}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://username:#githubcomment@github.com/Adrita-Khan/Tremor-Activity-Analysts.git\n\n\n#we are just pullingb this from a private github repo","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:32.556436Z","iopub.status.idle":"2025-02-27T17:28:32.556707Z","shell.execute_reply":"2025-02-27T17:28:32.556579Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\n\n# Paths\nsensor_data_path = \"/kaggle/working/Tremor-Activity-Analysts/TrainingDataPD25/users_timeXYZ/users\"\nactivity_labels_file = \"/kaggle/working/Tremor-Activity-Analysts/TrainingDataPD25/TrainActivities.csv\"\n\n# Step 1: Load Activity Labels\nactivities = pd.read_csv(activity_labels_file)\n\nactivities['Started'] = pd.to_datetime(activities['Started'], format='%Y/%m/%d %H:%M', errors='coerce') \\\n    .dt.tz_localize('Asia/Tokyo') \\\n    .dt.tz_convert('UTC')\n\nactivities['Finished'] = pd.to_datetime(activities['Finished'], format='%Y/%m/%d %H:%M', errors='coerce') \\\n    .dt.tz_localize('Asia/Tokyo') \\\n    .dt.tz_convert('UTC')\n\nactivities[:3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T16:58:38.190457Z","iopub.execute_input":"2025-02-27T16:58:38.190785Z","iopub.status.idle":"2025-02-27T16:58:38.576348Z","shell.execute_reply.started":"2025-02-27T16:58:38.190756Z","shell.execute_reply":"2025-02-27T16:58:38.575638Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"        ID  Activity Type ID  \\\n0  1130251              2806   \n1  1130254              2807   \n2  1130257              2807   \n\n                                       Activity Type  \\\n0                    1 (FACING camera) Sit and stand   \n1  2 (FACING camera) both hands SHAKING (sitting ...   \n2  2 (FACING camera) both hands SHAKING (sitting ...   \n\n                    Started                  Finished          Updated Subject  \n0 2024-09-01 21:16:00+00:00 2024-09-01 21:16:00+00:00  2024/09/02 6:16     U22  \n1 2024-09-01 21:17:00+00:00 2024-09-01 21:17:00+00:00  2024/09/02 6:17     U22  \n2 2024-09-01 21:18:00+00:00 2024-09-01 21:18:00+00:00  2024/09/02 6:18     U22  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Activity Type ID</th>\n      <th>Activity Type</th>\n      <th>Started</th>\n      <th>Finished</th>\n      <th>Updated</th>\n      <th>Subject</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1130251</td>\n      <td>2806</td>\n      <td>1 (FACING camera) Sit and stand</td>\n      <td>2024-09-01 21:16:00+00:00</td>\n      <td>2024-09-01 21:16:00+00:00</td>\n      <td>2024/09/02 6:16</td>\n      <td>U22</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1130254</td>\n      <td>2807</td>\n      <td>2 (FACING camera) both hands SHAKING (sitting ...</td>\n      <td>2024-09-01 21:17:00+00:00</td>\n      <td>2024-09-01 21:17:00+00:00</td>\n      <td>2024/09/02 6:17</td>\n      <td>U22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1130257</td>\n      <td>2807</td>\n      <td>2 (FACING camera) both hands SHAKING (sitting ...</td>\n      <td>2024-09-01 21:18:00+00:00</td>\n      <td>2024-09-01 21:18:00+00:00</td>\n      <td>2024/09/02 6:18</td>\n      <td>U22</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport glob\n\nprint(\"Loading sensor data...\")\n\n# Step 2: Load and Collect all sensor file paths\nsensor_files = glob.glob(os.path.join(sensor_data_path, \"*/*.csv\"))\nsensor_data_list = []\n\nfor file_path in sensor_files:\n    # Read sensor data\n    df = pd.read_csv(file_path, header=None, names=['RandomID', 'Timestamp', 'X', 'Y', 'Z'])\n    \n    # Convert timestamp format\n    try:\n        df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%dT%H:%M:%S.%f%z', utc=True)\n    except Exception as e:\n        print(f\"Error parsing timestamp in {file_path}: {e}\")\n        continue\n\n    df.drop(columns=['RandomID'], inplace=True)\n    sensor_data_list.append(df)\n\n# Combine all sensor data\nif sensor_data_list:\n    sensor_data = pd.concat(sensor_data_list, ignore_index=True)\n    print(f\"Total loaded sensor data: {sensor_data.shape}\")\nelse:\n    print(\"No valid sensor data found. Exiting.\")\n    exit()\n\n# Step 3: Match Sensor Data with Activities by TIMESTAMP\nprint(\"Matching sensor data with activity labels...\")\n\nmatched_data_list = []\n\nfor _, activity in activities.iterrows():\n    start_time, end_time, subject = activity['Started'], activity['Finished'], activity['Subject']\n\n    # Find sensor data that falls within the activity time window\n    mask = (sensor_data['Timestamp'] >= start_time) & (sensor_data['Timestamp'] <= end_time)\n    matched_activity_data = sensor_data[mask].copy()\n    \n    if not matched_activity_data.empty:\n        matched_activity_data['Activity'] = activity['Activity Type']\n        matched_activity_data['Subject'] = subject  # Keep track of Subject\n        matched_data_list.append(matched_activity_data)\n        print(f\"Matched {len(matched_activity_data)} rows for {activity['Activity Type']} (Subject {subject}).\")\n\n# Step 4: Save Final Matched Data\nif matched_data_list:\n    final_data = pd.concat(matched_data_list, ignore_index=True)\n    print(f\"Final matched data shape: {final_data.shape}\")\n    final_data.to_csv(\"/kaggle/working/Tremor-Activity-Analysts/Matched_Sensor_Activities.csv\", index=False)\n    print(\"Saved matched sensor data.\")\nelse:\n    print(\"No matching sensor data found for any activities.\")\n\nprint(\"Processing complete.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T16:58:43.257151Z","iopub.execute_input":"2025-02-27T16:58:43.257505Z","iopub.status.idle":"2025-02-27T16:59:08.881270Z","shell.execute_reply.started":"2025-02-27T16:58:43.257475Z","shell.execute_reply":"2025-02-27T16:59:08.880372Z"}},"outputs":[{"name":"stdout","text":"Loading sensor data...\nTotal loaded sensor data: (2045326, 4)\nMatching sensor data with activity labels...\nMatched 450 rows for 2 (FACING camera) both hands SHAKING (sitting position) (Subject U22).\nMatched 451 rows for 3 Stand up from chair - both hands with SHAKING (Subject U22).\nMatched 459 rows for 4 (Sideway) Sit & stand (Subject U22).\nMatched 450 rows for 5 (Sideway) both hands SHAKING (sitting) (Subject U22).\nMatched 450 rows for 6 (Sideway) STAND up with - both hands SHAKING (Subject U22).\nMatched 551 rows for 9 Walk & STOP/frozen, full body shaking, rotate then return back (Subject U22).\nMatched 552 rows for 10 Slow walk (SHAKING hands/body, tiny step, head forward) (Subject U22).\nMatched 450 rows for 10 Slow walk (SHAKING hands/body, tiny step, head forward) (Subject U22).\nMatched 550 rows for 10 Slow walk (SHAKING hands/body, tiny step, head forward) (Subject U22).\nMatched 449 rows for 3 Stand up from chair - both hands with SHAKING (Subject U21).\nMatched 499 rows for 6 (Sideway) STAND up with - both hands SHAKING (Subject U21).\nMatched 653 rows for 6 (Sideway) STAND up with - both hands SHAKING (Subject U21).\nMatched 530 rows for 9 Walk & STOP/frozen, full body shaking, rotate then return back (Subject U21).\nMatched 461 rows for 3 Stand up from chair - both hands with SHAKING (Subject U4).\nMatched 550 rows for 4 (Sideway) Sit & stand (Subject U4).\nMatched 451 rows for 6 (Sideway) STAND up with - both hands SHAKING (Subject U4).\nMatched 1 rows for 6 (Sideway) STAND up with - both hands SHAKING (Subject U4).\nMatched 649 rows for 5 (Sideway) both hands SHAKING (sitting) (Subject U4).\nMatched 450 rows for 7 Cool down - sitting/relax (Subject U4).\nMatched 550 rows for 9 Walk & STOP/frozen, full body shaking, rotate then return back (Subject U4).\nMatched 461 rows for 9 Walk & STOP/frozen, full body shaking, rotate then return back (Subject U4).\nMatched 527 rows for 10 Slow walk (SHAKING hands/body, tiny step, head forward) (Subject U4).\nMatched 731 rows for 10 Slow walk (SHAKING hands/body, tiny step, head forward) (Subject U4).\nMatched 460 rows for 1 (FACING camera) Sit and stand (Subject U5).\nMatched 463 rows for 2 (FACING camera) both hands SHAKING (sitting position) (Subject U5).\nMatched 450 rows for 5 (Sideway) both hands SHAKING (sitting) (Subject U5).\nMatched 641 rows for 6 (Sideway) STAND up with - both hands SHAKING (Subject U5).\nMatched 451 rows for 8 Walk (LEFT --> Right --> Left) (Subject U5).\nMatched 477 rows for 9 Walk & STOP/frozen, full body shaking, rotate then return back (Subject U5).\nMatched 783 rows for 10 Slow walk (SHAKING hands/body, tiny step, head forward) (Subject U5).\nMatched 1463 rows for 10 Slow walk (SHAKING hands/body, tiny step, head forward) (Subject U5).\nMatched 450 rows for 4 (Sideway) Sit & stand (Subject U1).\nMatched 449 rows for 7 Cool down - sitting/relax (Subject U1).\nMatched 481 rows for 9 Walk & STOP/frozen, full body shaking, rotate then return back (Subject U1).\nMatched 489 rows for 10 Slow walk (SHAKING hands/body, tiny step, head forward) (Subject U1).\nMatched 550 rows for 2 (FACING camera) both hands SHAKING (sitting position) (Subject U2).\nMatched 451 rows for 3 Stand up from chair - both hands with SHAKING (Subject U2).\nMatched 447 rows for 6 (Sideway) STAND up with - both hands SHAKING (Subject U2).\nMatched 463 rows for 5 (Sideway) both hands SHAKING (sitting) (Subject U2).\nMatched 448 rows for 8 Walk (LEFT --> Right --> Left) (Subject U2).\nMatched 550 rows for 9 Walk & STOP/frozen, full body shaking, rotate then return back (Subject U2).\nMatched 674 rows for 10 Slow walk (SHAKING hands/body, tiny step, head forward) (Subject U2).\nMatched 1685 rows for 2 (FACING camera) both hands SHAKING (sitting position) (Subject U3).\nMatched 1685 rows for 2 (FACING camera) both hands SHAKING (sitting position) (Subject U3).\nMatched 1396 rows for 5 (Sideway) both hands SHAKING (sitting) (Subject U3).\nMatched 1 rows for 1 (FACING camera) Sit and stand (Subject U6).\nMatched 1 rows for 1 (FACING camera) Sit and stand (Subject U6).\nMatched 2491 rows for 2 (FACING camera) both hands SHAKING (sitting position) (Subject U6).\nMatched 3102 rows for 3 Stand up from chair - both hands with SHAKING (Subject U6).\nMatched 3140 rows for 4 (Sideway) Sit & stand (Subject U6).\nMatched 3140 rows for 6 (Sideway) STAND up with - both hands SHAKING (Subject U6).\nMatched 3145 rows for 7 Cool down - sitting/relax (Subject U6).\nMatched 3145 rows for 8 Walk (LEFT --> Right --> Left) (Subject U6).\nMatched 3145 rows for 9 Walk & STOP/frozen, full body shaking, rotate then return back (Subject U6).\nMatched 3140 rows for 9 Walk & STOP/frozen, full body shaking, rotate then return back (Subject U6).\nMatched 3145 rows for 9 Walk & STOP/frozen, full body shaking, rotate then return back (Subject U6).\nMatched 3144 rows for 10 Slow walk (SHAKING hands/body, tiny step, head forward) (Subject U6).\nMatched 3144 rows for 10 Slow walk (SHAKING hands/body, tiny step, head forward) (Subject U6).\nMatched 3144 rows for 2 (FACING camera) both hands SHAKING (sitting position) (Subject U3).\nMatched 3145 rows for 3 Stand up from chair - both hands with SHAKING (Subject U3).\nMatched 3140 rows for 4 (Sideway) Sit & stand (Subject U3).\nMatched 1 rows for 4 (Sideway) Sit & stand (Subject U3).\nMatched 1 rows for 4 (Sideway) Sit & stand (Subject U3).\nMatched 3145 rows for 5 (Sideway) both hands SHAKING (sitting) (Subject U3).\nMatched 3141 rows for 8 Walk (LEFT --> Right --> Left) (Subject U3).\nMatched 3143 rows for 9 Walk & STOP/frozen, full body shaking, rotate then return back (Subject U3).\nMatched 3145 rows for 9 Walk & STOP/frozen, full body shaking, rotate then return back (Subject U3).\nMatched 3145 rows for 10 Slow walk (SHAKING hands/body, tiny step, head forward) (Subject U3).\nMatched 3142 rows for 10 Slow walk (SHAKING hands/body, tiny step, head forward) (Subject U3).\nMatched 3142 rows for 10 Slow walk (SHAKING hands/body, tiny step, head forward) (Subject U3).\nMatched 3145 rows for 3 Stand up from chair - both hands with SHAKING (Subject U7).\nMatched 1 rows for 4 (Sideway) Sit & stand (Subject U7).\nMatched 1 rows for 4 (Sideway) Sit & stand (Subject U7).\nMatched 1 rows for 4 (Sideway) Sit & stand (Subject U7).\nMatched 1 rows for 5 (Sideway) both hands SHAKING (sitting) (Subject U7).\nMatched 3142 rows for 6 (Sideway) STAND up with - both hands SHAKING (Subject U7).\nMatched 3143 rows for 9 Walk & STOP/frozen, full body shaking, rotate then return back (Subject U7).\nMatched 3145 rows for 10 Slow walk (SHAKING hands/body, tiny step, head forward) (Subject U7).\nFinal matched data shape: (104627, 6)\nSaved matched sensor data.\nProcessing complete.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"final_data[100:103]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:01:24.896816Z","iopub.execute_input":"2025-02-27T17:01:24.897361Z","iopub.status.idle":"2025-02-27T17:01:24.912142Z","shell.execute_reply.started":"2025-02-27T17:01:24.897315Z","shell.execute_reply":"2025-02-27T17:01:24.911254Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                           Timestamp      X      Y      Z  \\\n100 2024-09-03 10:56:58.569000+00:00  0.010  2.531  9.477   \n101 2024-09-03 10:56:58.704000+00:00 -0.043  2.621  9.449   \n102 2024-09-03 10:56:58.838000+00:00  0.228  3.090  8.873   \n\n                                              Activity Subject  \n100  2 (FACING camera) both hands SHAKING (sitting ...     U22  \n101  2 (FACING camera) both hands SHAKING (sitting ...     U22  \n102  2 (FACING camera) both hands SHAKING (sitting ...     U22  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>X</th>\n      <th>Y</th>\n      <th>Z</th>\n      <th>Activity</th>\n      <th>Subject</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>100</th>\n      <td>2024-09-03 10:56:58.569000+00:00</td>\n      <td>0.010</td>\n      <td>2.531</td>\n      <td>9.477</td>\n      <td>2 (FACING camera) both hands SHAKING (sitting ...</td>\n      <td>U22</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>2024-09-03 10:56:58.704000+00:00</td>\n      <td>-0.043</td>\n      <td>2.621</td>\n      <td>9.449</td>\n      <td>2 (FACING camera) both hands SHAKING (sitting ...</td>\n      <td>U22</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>2024-09-03 10:56:58.838000+00:00</td>\n      <td>0.228</td>\n      <td>3.090</td>\n      <td>8.873</td>\n      <td>2 (FACING camera) both hands SHAKING (sitting ...</td>\n      <td>U22</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nimport numpy as np\nimport pandas as pd\n\n# Load data\ndf = final_data.copy()\n\n# Encode activities (labels)\nlabel_encoder = LabelEncoder()\ndf['Activity_Label'] = label_encoder.fit_transform(df['Activity'])\n\n# Normalize sensor values\nscaler = StandardScaler()\ndf[['X', 'Y', 'Z']] = scaler.fit_transform(df[['X', 'Y', 'Z']])\n\n# Group by Subject & Time Windows\ntime_window = 10  # 10 sensor readings per sequence\nsequences, labels = [], []\n\nfor subject, group in df.groupby('Subject'):\n    group = group.sort_values('Timestamp')\n    sensor_values = group[['X', 'Y', 'Z']].values\n    activity_labels = group['Activity_Label'].values\n    \n    # Create sequences of length `time_window`\n    for i in range(len(group) - time_window):\n        sequences.append(sensor_values[i:i+time_window])\n        labels.append(activity_labels[i+time_window])\n\nsequences = np.array(sequences)\nlabels = np.array(labels)\n\n# Convert to PyTorch tensors\nX_tensor = torch.tensor(sequences, dtype=torch.float32)\ny_tensor = torch.tensor(labels, dtype=torch.long)\n\n# **Split into Train (80%) and Validation (20%)**\ntrain_size = int(0.8 * len(X_tensor))\nval_size = len(X_tensor) - train_size\n\ntrain_dataset, val_dataset = random_split(list(zip(X_tensor, y_tensor)), [train_size, val_size])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:04:27.601282Z","iopub.execute_input":"2025-02-27T17:04:27.601631Z","iopub.status.idle":"2025-02-27T17:04:32.277621Z","shell.execute_reply.started":"2025-02-27T17:04:27.601609Z","shell.execute_reply":"2025-02-27T17:04:32.276658Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:04:48.837898Z","iopub.execute_input":"2025-02-27T17:04:48.838437Z","iopub.status.idle":"2025-02-27T17:04:48.927039Z","shell.execute_reply.started":"2025-02-27T17:04:48.838407Z","shell.execute_reply":"2025-02-27T17:04:48.925918Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"class TransformerModel(nn.Module):\n    def __init__(self, input_dim=3, seq_len=10, num_classes=5, d_model=64, nhead=4, num_layers=2):\n        super(TransformerModel, self).__init__()\n        self.embedding = nn.Linear(input_dim, d_model)\n        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n        self.fc = nn.Linear(d_model, num_classes)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x = self.transformer_encoder(x)\n        x = x.mean(dim=1)\n        return self.fc(x)\n\n# Initialize Model on GPU\nmodel = TransformerModel(num_classes=len(label_encoder.classes_)).to(device)\n\n# Loss & Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:04:52.251915Z","iopub.execute_input":"2025-02-27T17:04:52.252324Z","iopub.status.idle":"2025-02-27T17:04:54.501363Z","shell.execute_reply.started":"2025-02-27T17:04:52.252290Z","shell.execute_reply":"2025-02-27T17:04:54.500719Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n# Training loop with validation\nepochs = 100\nbest_val_loss = float(\"inf\")\npatience = 10  # Stop training if no improvement in `patience` epochs\npatience_counter = 0\n\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n\n    for batch_X, batch_y in train_loader:\n        batch_X, batch_y = batch_X.to(device), batch_y.to(device)  # Move to GPU\n        \n        optimizer.zero_grad()\n        outputs = model(batch_X)\n        loss = criterion(outputs, batch_y)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    # **Validation**\n    model.eval()\n    val_loss = 0\n    correct, total = 0, 0\n    \n    with torch.no_grad():\n        for batch_X, batch_y in val_loader:\n            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n            outputs = model(batch_X)\n            loss = criterion(outputs, batch_y)\n            val_loss += loss.item()\n\n            # Accuracy Calculation\n            predictions = torch.argmax(outputs, dim=1)\n            correct += (predictions == batch_y).sum().item()\n            total += batch_y.size(0)\n\n    val_loss /= len(val_loader)\n    val_accuracy = correct / total\n\n    print(f\"Epoch {epoch+1}: Train Loss = {total_loss:.4f}, Val Loss = {val_loss:.4f}, Val Acc = {val_accuracy:.4f}\")\n\n    # **Early Stopping**\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        patience_counter = 0\n        torch.save(model.state_dict(), \"best_model.pth\")  # Save best model\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(\"Early stopping triggered!\")\n            break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:29:33.251451Z","iopub.execute_input":"2025-02-27T17:29:33.251843Z","iopub.status.idle":"2025-02-27T17:47:44.803647Z","shell.execute_reply.started":"2025-02-27T17:29:33.251813Z","shell.execute_reply":"2025-02-27T17:47:44.802600Z"}},"outputs":[{"name":"stdout","text":"Epoch 1: Train Loss = 2248.5474, Val Loss = 0.7955, Val Acc = 0.6993\nEpoch 2: Train Loss = 2229.2648, Val Loss = 0.7963, Val Acc = 0.6940\nEpoch 3: Train Loss = 2223.0581, Val Loss = 0.7760, Val Acc = 0.7020\nEpoch 4: Train Loss = 2214.7306, Val Loss = 0.7909, Val Acc = 0.6983\nEpoch 5: Train Loss = 2204.3128, Val Loss = 0.7581, Val Acc = 0.7080\nEpoch 6: Train Loss = 2194.2499, Val Loss = 0.7746, Val Acc = 0.7045\nEpoch 7: Train Loss = 2186.2086, Val Loss = 0.7565, Val Acc = 0.7137\nEpoch 8: Train Loss = 2177.0147, Val Loss = 0.7868, Val Acc = 0.6976\nEpoch 9: Train Loss = 2166.5703, Val Loss = 0.7707, Val Acc = 0.7077\nEpoch 10: Train Loss = 2159.2721, Val Loss = 0.7479, Val Acc = 0.7116\nEpoch 11: Train Loss = 2144.4478, Val Loss = 0.7939, Val Acc = 0.6969\nEpoch 12: Train Loss = 2151.7772, Val Loss = 0.7505, Val Acc = 0.7111\nEpoch 13: Train Loss = 2140.7035, Val Loss = 0.7393, Val Acc = 0.7161\nEpoch 14: Train Loss = 2126.1306, Val Loss = 0.7467, Val Acc = 0.7152\nEpoch 15: Train Loss = 2124.8629, Val Loss = 0.7331, Val Acc = 0.7226\nEpoch 16: Train Loss = 2104.4624, Val Loss = 0.7442, Val Acc = 0.7175\nEpoch 17: Train Loss = 2109.4008, Val Loss = 0.7326, Val Acc = 0.7165\nEpoch 18: Train Loss = 2095.7287, Val Loss = 0.7233, Val Acc = 0.7209\nEpoch 19: Train Loss = 2095.3444, Val Loss = 0.7440, Val Acc = 0.7143\nEpoch 20: Train Loss = 2079.4938, Val Loss = 0.7190, Val Acc = 0.7246\nEpoch 21: Train Loss = 2085.3142, Val Loss = 0.7337, Val Acc = 0.7201\nEpoch 22: Train Loss = 2065.5909, Val Loss = 0.6997, Val Acc = 0.7342\nEpoch 23: Train Loss = 2069.3424, Val Loss = 0.7057, Val Acc = 0.7266\nEpoch 24: Train Loss = 2057.8685, Val Loss = 0.7013, Val Acc = 0.7316\nEpoch 25: Train Loss = 2047.9736, Val Loss = 0.6917, Val Acc = 0.7361\nEpoch 26: Train Loss = 2044.7320, Val Loss = 0.7126, Val Acc = 0.7289\nEpoch 27: Train Loss = 2042.8841, Val Loss = 0.7011, Val Acc = 0.7290\nEpoch 28: Train Loss = 2030.4044, Val Loss = 0.6882, Val Acc = 0.7405\nEpoch 29: Train Loss = 2014.9316, Val Loss = 0.7104, Val Acc = 0.7292\nEpoch 30: Train Loss = 2018.3199, Val Loss = 0.6908, Val Acc = 0.7374\nEpoch 31: Train Loss = 2013.9809, Val Loss = 0.6767, Val Acc = 0.7417\nEpoch 32: Train Loss = 2012.7771, Val Loss = 0.6796, Val Acc = 0.7410\nEpoch 33: Train Loss = 2005.4208, Val Loss = 0.6892, Val Acc = 0.7338\nEpoch 34: Train Loss = 1986.1760, Val Loss = 0.6816, Val Acc = 0.7415\nEpoch 35: Train Loss = 1988.8864, Val Loss = 0.6649, Val Acc = 0.7462\nEpoch 36: Train Loss = 1981.2387, Val Loss = 0.6720, Val Acc = 0.7417\nEpoch 37: Train Loss = 1983.7135, Val Loss = 0.6647, Val Acc = 0.7426\nEpoch 38: Train Loss = 1975.3457, Val Loss = 0.6658, Val Acc = 0.7485\nEpoch 39: Train Loss = 1975.4817, Val Loss = 0.6729, Val Acc = 0.7445\nEpoch 40: Train Loss = 1964.1287, Val Loss = 0.6525, Val Acc = 0.7505\nEpoch 41: Train Loss = 1968.8500, Val Loss = 0.6528, Val Acc = 0.7528\nEpoch 42: Train Loss = 1954.4938, Val Loss = 0.6566, Val Acc = 0.7508\nEpoch 43: Train Loss = 1944.7331, Val Loss = 0.6694, Val Acc = 0.7432\nEpoch 44: Train Loss = 1943.0548, Val Loss = 0.6701, Val Acc = 0.7433\nEpoch 45: Train Loss = 1936.4548, Val Loss = 0.6496, Val Acc = 0.7509\nEpoch 46: Train Loss = 1925.5114, Val Loss = 0.6606, Val Acc = 0.7500\nEpoch 47: Train Loss = 1935.8836, Val Loss = 0.6467, Val Acc = 0.7559\nEpoch 48: Train Loss = 1917.6134, Val Loss = 0.6489, Val Acc = 0.7525\nEpoch 49: Train Loss = 1918.6839, Val Loss = 0.6339, Val Acc = 0.7521\nEpoch 50: Train Loss = 1914.2414, Val Loss = 0.6551, Val Acc = 0.7488\nEpoch 51: Train Loss = 1912.3713, Val Loss = 0.6462, Val Acc = 0.7535\nEpoch 52: Train Loss = 1907.4092, Val Loss = 0.6445, Val Acc = 0.7556\nEpoch 53: Train Loss = 1898.2136, Val Loss = 0.6190, Val Acc = 0.7648\nEpoch 54: Train Loss = 1891.2411, Val Loss = 0.6287, Val Acc = 0.7616\nEpoch 55: Train Loss = 1882.8311, Val Loss = 0.6433, Val Acc = 0.7567\nEpoch 56: Train Loss = 1884.7720, Val Loss = 0.6297, Val Acc = 0.7588\nEpoch 57: Train Loss = 1877.4838, Val Loss = 0.6235, Val Acc = 0.7633\nEpoch 58: Train Loss = 1874.6321, Val Loss = 0.6291, Val Acc = 0.7599\nEpoch 59: Train Loss = 1871.2744, Val Loss = 0.6144, Val Acc = 0.7651\nEpoch 60: Train Loss = 1875.4052, Val Loss = 0.6404, Val Acc = 0.7532\nEpoch 61: Train Loss = 1869.5711, Val Loss = 0.6028, Val Acc = 0.7701\nEpoch 62: Train Loss = 1858.4659, Val Loss = 0.6237, Val Acc = 0.7638\nEpoch 63: Train Loss = 1867.1859, Val Loss = 0.6294, Val Acc = 0.7605\nEpoch 64: Train Loss = 1853.8228, Val Loss = 0.6214, Val Acc = 0.7654\nEpoch 65: Train Loss = 1854.4984, Val Loss = 0.6143, Val Acc = 0.7668\nEpoch 66: Train Loss = 1853.3820, Val Loss = 0.6101, Val Acc = 0.7701\nEpoch 67: Train Loss = 1843.1861, Val Loss = 0.6147, Val Acc = 0.7636\nEpoch 68: Train Loss = 1831.2806, Val Loss = 0.6105, Val Acc = 0.7688\nEpoch 69: Train Loss = 1828.5325, Val Loss = 0.6301, Val Acc = 0.7602\nEpoch 70: Train Loss = 1832.1443, Val Loss = 0.6036, Val Acc = 0.7672\nEpoch 71: Train Loss = 1826.4002, Val Loss = 0.6377, Val Acc = 0.7561\nEarly stopping triggered!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport numpy as np\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load test data\ntest_data = pd.read_csv(\"/kaggle/input/pd-test-data/TestActivities-20240920.csv\")\n\n# Convert timestamps\ntest_data['Started'] = pd.to_datetime(test_data['Started'], format='%Y/%m/%d %H:%M', errors='coerce') \\\n    .dt.tz_localize('Asia/Tokyo') \\\n    .dt.tz_convert('UTC')\n\ntest_data['Finished'] = pd.to_datetime(test_data['Finished'], format='%Y/%m/%d %H:%M', errors='coerce') \\\n    .dt.tz_localize('Asia/Tokyo') \\\n    .dt.tz_convert('UTC')\n\n# Load model\nmodel.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\nmodel.to(device)\nmodel.eval()\n\n# Debug timestamp range\nprint(f\"Test Data Time Range: {test_data['Started'].min()} to {test_data['Finished'].max()}\")\nprint(f\"Sensor Data Time Range: {sensor_data['Timestamp'].min()} to {sensor_data['Timestamp'].max()}\")\n\ndef predict_activity(sensor_data):\n    if sensor_data.empty:\n        return \"Unknown\"\n\n    sensor_data = sensor_data.copy()\n    sensor_data.loc[:, ['X', 'Y', 'Z']] = scaler.transform(sensor_data[['X', 'Y', 'Z']])\n\n    sequences = []\n    for i in range(len(sensor_data) - time_window):\n        sequences.append(sensor_data[['X', 'Y', 'Z']].values[i:i+time_window])\n\n    sequences = np.array(sequences)\n\n    if sequences.shape[0] == 0:\n        return \"Unknown\"\n\n    batch_size = 512\n    predictions = []\n\n    for i in range(0, len(sequences), batch_size):\n        batch = torch.tensor(sequences[i:i+batch_size], dtype=torch.float32).to(device)\n        \n        with torch.no_grad():\n            batch_predictions = model(batch)\n            predicted_labels = torch.argmax(batch_predictions, dim=1).cpu().numpy()\n        \n        predictions.extend(predicted_labels)\n\n    return label_encoder.inverse_transform(predictions)[0]\n\npredicted_activities = []\n\nfor _, row in test_data.iterrows():\n    buffer = pd.Timedelta(seconds=1)  # Allow +/- 1 seconds to match\n    mask = (sensor_data['Timestamp'] >= row['Started'] - buffer) & (sensor_data['Timestamp'] <= row['Finished'] + buffer)\n    matched_sensors = sensor_data.loc[mask]\n\n    print(f\"ID {row['ID']} - Matching sensor count: {matched_sensors.shape[0]}\")  # Debugging\n\n    predicted_activity = predict_activity(matched_sensors)\n    predicted_activities.append(predicted_activity)\n\ntest_data.loc[:, 'Predicted_Activity'] = predicted_activities\n\ntest_data.to_csv(\"Predicted_Activities.csv\", index=False)\n\nprint(\"Prediction complete. Results saved to 'Predicted_Activities.csv'.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:53:52.612385Z","iopub.execute_input":"2025-02-27T17:53:52.612753Z","iopub.status.idle":"2025-02-27T17:54:35.104623Z","shell.execute_reply.started":"2025-02-27T17:53:52.612723Z","shell.execute_reply":"2025-02-27T17:54:35.103654Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-14-ae16cd4b44ca>:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\n","output_type":"stream"},{"name":"stdout","text":"Test Data Time Range: 2024-09-08 22:47:00+00:00 to 2024-09-12 19:38:00+00:00\nSensor Data Time Range: 2024-09-01 21:25:07.752000+00:00 to 2024-09-12 20:19:47.443000+00:00\nID 1156840 - Matching sensor count: 34\nID 1156841 - Matching sensor count: 34\nID 1156842 - Matching sensor count: 1082\nID 1156843 - Matching sensor count: 35\nID 1156844 - Matching sensor count: 35\nID 1156845 - Matching sensor count: 35\nID 1156846 - Matching sensor count: 35\nID 1156847 - Matching sensor count: 35\nID 1156848 - Matching sensor count: 2220\nID 1156849 - Matching sensor count: 0\nID 1156850 - Matching sensor count: 0\nID 1156851 - Matching sensor count: 0\nID 1160415 - Matching sensor count: 0\nID 1164231 - Matching sensor count: 105\nID 1164232 - Matching sensor count: 105\nID 1164233 - Matching sensor count: 105\nID 1164234 - Matching sensor count: 105\nID 1164235 - Matching sensor count: 105\nID 1164236 - Matching sensor count: 106\nID 1164237 - Matching sensor count: 106\nID 1164238 - Matching sensor count: 3250\nID 1164239 - Matching sensor count: 105\nID 1164240 - Matching sensor count: 105\nID 1164241 - Matching sensor count: 105\nID 1164242 - Matching sensor count: 106\nID 1164243 - Matching sensor count: 106\nID 1164245 - Matching sensor count: 106\nID 1164246 - Matching sensor count: 106\nID 1164247 - Matching sensor count: 105\nID 1164248 - Matching sensor count: 105\nID 1164250 - Matching sensor count: 105\nID 1164252 - Matching sensor count: 105\nID 1164253 - Matching sensor count: 3245\nID 1164254 - Matching sensor count: 104\nID 1164255 - Matching sensor count: 104\nID 1164256 - Matching sensor count: 104\nID 1164257 - Matching sensor count: 3244\nID 1164258 - Matching sensor count: 3249\nID 1164259 - Matching sensor count: 3250\nID 1164260 - Matching sensor count: 105\nID 1164268 - Matching sensor count: 3246\nID 1164281 - Matching sensor count: 105\nID 1166499 - Matching sensor count: 105\nID 1166504 - Matching sensor count: 103\nID 1166505 - Matching sensor count: 103\nID 1166506 - Matching sensor count: 3248\nID 1166507 - Matching sensor count: 104\nID 1166508 - Matching sensor count: 105\nID 1166509 - Matching sensor count: 105\nID 1166510 - Matching sensor count: 35\nID 1166511 - Matching sensor count: 35\nID 1166512 - Matching sensor count: 1818\nID 1166513 - Matching sensor count: 104\nID 1166514 - Matching sensor count: 3246\nID 1166515 - Matching sensor count: 105\nID 1166516 - Matching sensor count: 105\nID 1166517 - Matching sensor count: 3250\nID 1166518 - Matching sensor count: 105\nID 1166519 - Matching sensor count: 102\nID 1166520 - Matching sensor count: 102\nID 1166521 - Matching sensor count: 3244\nID 1166522 - Matching sensor count: 104\nID 1166523 - Matching sensor count: 3249\nID 1166524 - Matching sensor count: 105\nID 1166525 - Matching sensor count: 105\nID 1166526 - Matching sensor count: 101\nID 1166527 - Matching sensor count: 105\nID 1166528 - Matching sensor count: 3249\nID 1166529 - Matching sensor count: 0\nID 1166530 - Matching sensor count: 104\nID 1166531 - Matching sensor count: 105\nID 1166532 - Matching sensor count: 6389\nID 1166533 - Matching sensor count: 105\nID 1166540 - Matching sensor count: 105\nID 1166542 - Matching sensor count: 105\nID 1166551 - Matching sensor count: 3249\nID 1167268 - Matching sensor count: 104\nID 1167269 - Matching sensor count: 35\nID 1167270 - Matching sensor count: 35\nID 1167273 - Matching sensor count: 35\nID 1167274 - Matching sensor count: 35\nID 1167275 - Matching sensor count: 1323\nID 1167276 - Matching sensor count: 101\nID 1167277 - Matching sensor count: 1270\nID 1167278 - Matching sensor count: 1270\nID 1167279 - Matching sensor count: 35\nID 1167280 - Matching sensor count: 1443\nID 1167281 - Matching sensor count: 35\nID 1167282 - Matching sensor count: 35\nID 1167283 - Matching sensor count: 103\nID 1167284 - Matching sensor count: 103\nID 1167285 - Matching sensor count: 105\nID 1167286 - Matching sensor count: 1256\nID 1167287 - Matching sensor count: 35\nID 1167288 - Matching sensor count: 35\nID 1167289 - Matching sensor count: 35\nID 1167290 - Matching sensor count: 1445\nID 1167291 - Matching sensor count: 35\nID 1167292 - Matching sensor count: 35\nID 1167293 - Matching sensor count: 1322\nID 1167294 - Matching sensor count: 35\nID 1167295 - Matching sensor count: 35\nID 1167296 - Matching sensor count: 1444\nID 1167297 - Matching sensor count: 91\nID 1167300 - Matching sensor count: 35\nID 1167309 - Matching sensor count: 35\nID 1167320 - Matching sensor count: 105\nID 1171436 - Matching sensor count: 51\nID 1171440 - Matching sensor count: 105\nID 1171441 - Matching sensor count: 105\nID 1171442 - Matching sensor count: 105\nID 1171443 - Matching sensor count: 105\nID 1171444 - Matching sensor count: 105\nID 1171445 - Matching sensor count: 105\nID 1171446 - Matching sensor count: 100\nID 1171447 - Matching sensor count: 100\nID 1171448 - Matching sensor count: 103\nID 1171449 - Matching sensor count: 3247\nID 1171450 - Matching sensor count: 107\nID 1171451 - Matching sensor count: 107\nID 1171452 - Matching sensor count: 107\nID 1171453 - Matching sensor count: 107\nID 1171454 - Matching sensor count: 3252\nID 1171455 - Matching sensor count: 106\nID 1171456 - Matching sensor count: 106\nID 1171457 - Matching sensor count: 106\nID 1171458 - Matching sensor count: 106\nID 1171459 - Matching sensor count: 109\nID 1171460 - Matching sensor count: 109\nID 1171461 - Matching sensor count: 109\nID 1171462 - Matching sensor count: 104\nID 1171463 - Matching sensor count: 3250\nID 1171464 - Matching sensor count: 104\nID 1171465 - Matching sensor count: 3244\nID 1171466 - Matching sensor count: 110\nID 1171467 - Matching sensor count: 3250\nID 1171517 - Matching sensor count: 102\nID 1171518 - Matching sensor count: 102\nID 1171519 - Matching sensor count: 102\nID 1171520 - Matching sensor count: 105\nID 1171521 - Matching sensor count: 105\nID 1171522 - Matching sensor count: 105\nID 1171523 - Matching sensor count: 105\nID 1171524 - Matching sensor count: 105\nID 1171525 - Matching sensor count: 105\nID 1171526 - Matching sensor count: 110\nID 1171527 - Matching sensor count: 110\nID 1171528 - Matching sensor count: 110\nID 1171529 - Matching sensor count: 3250\nID 1171530 - Matching sensor count: 105\nID 1171531 - Matching sensor count: 105\nID 1171532 - Matching sensor count: 3247\nID 1171533 - Matching sensor count: 103\nID 1171534 - Matching sensor count: 103\nID 1171535 - Matching sensor count: 103\nID 1171536 - Matching sensor count: 105\nID 1171537 - Matching sensor count: 105\nID 1171538 - Matching sensor count: 3248\nID 1171539 - Matching sensor count: 3250\nID 1171540 - Matching sensor count: 105\nID 1171541 - Matching sensor count: 3250\nID 1171542 - Matching sensor count: 105\nID 1171543 - Matching sensor count: 3245\nID 1171544 - Matching sensor count: 105\nPrediction complete. Results saved to 'Predicted_Activities.csv'.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"test_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:56:24.062604Z","iopub.execute_input":"2025-02-27T17:56:24.062984Z","iopub.status.idle":"2025-02-27T17:56:24.074712Z","shell.execute_reply.started":"2025-02-27T17:56:24.062955Z","shell.execute_reply":"2025-02-27T17:56:24.073783Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"          ID                   Started                  Finished  \\\n0    1156840 2024-09-08 22:47:00+00:00 2024-09-08 22:47:00+00:00   \n1    1156841 2024-09-08 22:47:00+00:00 2024-09-08 22:47:00+00:00   \n2    1156842 2024-09-08 22:47:00+00:00 2024-09-08 22:48:00+00:00   \n3    1156843 2024-09-08 22:48:00+00:00 2024-09-08 22:48:00+00:00   \n4    1156844 2024-09-08 22:48:00+00:00 2024-09-08 22:48:00+00:00   \n..       ...                       ...                       ...   \n159  1171540 2024-09-12 19:36:00+00:00 2024-09-12 19:36:00+00:00   \n160  1171541 2024-09-12 19:36:00+00:00 2024-09-12 19:37:00+00:00   \n161  1171542 2024-09-12 19:37:00+00:00 2024-09-12 19:37:00+00:00   \n162  1171543 2024-09-12 19:37:00+00:00 2024-09-12 19:38:00+00:00   \n163  1171544 2024-09-12 19:38:00+00:00 2024-09-12 19:38:00+00:00   \n\n             Updated Subject  \\\n0    2024/09/09 7:47     U11   \n1    2024/09/09 7:47     U11   \n2    2024/09/09 7:48     U11   \n3    2024/09/09 7:48     U11   \n4    2024/09/09 7:48     U11   \n..               ...     ...   \n159  2024/09/13 4:36     U12   \n160  2024/09/13 4:37     U12   \n161  2024/09/13 4:37     U12   \n162  2024/09/13 4:38     U12   \n163  2024/09/13 4:38     U12   \n\n                                    Predicted_Activity  \n0    2 (FACING camera) both hands SHAKING (sitting ...  \n1    2 (FACING camera) both hands SHAKING (sitting ...  \n2       6 (Sideway) STAND up with - both hands SHAKING  \n3       6 (Sideway) STAND up with - both hands SHAKING  \n4       6 (Sideway) STAND up with - both hands SHAKING  \n..                                                 ...  \n159  10 Slow walk (SHAKING hands/body, tiny step, h...  \n160  10 Slow walk (SHAKING hands/body, tiny step, h...  \n161  10 Slow walk (SHAKING hands/body, tiny step, h...  \n162  9 Walk & STOP/frozen, full body shaking, rotat...  \n163  10 Slow walk (SHAKING hands/body, tiny step, h...  \n\n[164 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Started</th>\n      <th>Finished</th>\n      <th>Updated</th>\n      <th>Subject</th>\n      <th>Predicted_Activity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1156840</td>\n      <td>2024-09-08 22:47:00+00:00</td>\n      <td>2024-09-08 22:47:00+00:00</td>\n      <td>2024/09/09 7:47</td>\n      <td>U11</td>\n      <td>2 (FACING camera) both hands SHAKING (sitting ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1156841</td>\n      <td>2024-09-08 22:47:00+00:00</td>\n      <td>2024-09-08 22:47:00+00:00</td>\n      <td>2024/09/09 7:47</td>\n      <td>U11</td>\n      <td>2 (FACING camera) both hands SHAKING (sitting ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1156842</td>\n      <td>2024-09-08 22:47:00+00:00</td>\n      <td>2024-09-08 22:48:00+00:00</td>\n      <td>2024/09/09 7:48</td>\n      <td>U11</td>\n      <td>6 (Sideway) STAND up with - both hands SHAKING</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1156843</td>\n      <td>2024-09-08 22:48:00+00:00</td>\n      <td>2024-09-08 22:48:00+00:00</td>\n      <td>2024/09/09 7:48</td>\n      <td>U11</td>\n      <td>6 (Sideway) STAND up with - both hands SHAKING</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1156844</td>\n      <td>2024-09-08 22:48:00+00:00</td>\n      <td>2024-09-08 22:48:00+00:00</td>\n      <td>2024/09/09 7:48</td>\n      <td>U11</td>\n      <td>6 (Sideway) STAND up with - both hands SHAKING</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>159</th>\n      <td>1171540</td>\n      <td>2024-09-12 19:36:00+00:00</td>\n      <td>2024-09-12 19:36:00+00:00</td>\n      <td>2024/09/13 4:36</td>\n      <td>U12</td>\n      <td>10 Slow walk (SHAKING hands/body, tiny step, h...</td>\n    </tr>\n    <tr>\n      <th>160</th>\n      <td>1171541</td>\n      <td>2024-09-12 19:36:00+00:00</td>\n      <td>2024-09-12 19:37:00+00:00</td>\n      <td>2024/09/13 4:37</td>\n      <td>U12</td>\n      <td>10 Slow walk (SHAKING hands/body, tiny step, h...</td>\n    </tr>\n    <tr>\n      <th>161</th>\n      <td>1171542</td>\n      <td>2024-09-12 19:37:00+00:00</td>\n      <td>2024-09-12 19:37:00+00:00</td>\n      <td>2024/09/13 4:37</td>\n      <td>U12</td>\n      <td>10 Slow walk (SHAKING hands/body, tiny step, h...</td>\n    </tr>\n    <tr>\n      <th>162</th>\n      <td>1171543</td>\n      <td>2024-09-12 19:37:00+00:00</td>\n      <td>2024-09-12 19:38:00+00:00</td>\n      <td>2024/09/13 4:38</td>\n      <td>U12</td>\n      <td>9 Walk &amp; STOP/frozen, full body shaking, rotat...</td>\n    </tr>\n    <tr>\n      <th>163</th>\n      <td>1171544</td>\n      <td>2024-09-12 19:38:00+00:00</td>\n      <td>2024-09-12 19:38:00+00:00</td>\n      <td>2024/09/13 4:38</td>\n      <td>U12</td>\n      <td>10 Slow walk (SHAKING hands/body, tiny step, h...</td>\n    </tr>\n  </tbody>\n</table>\n<p>164 rows Ã— 6 columns</p>\n</div>"},"metadata":{}}],"execution_count":15}]}